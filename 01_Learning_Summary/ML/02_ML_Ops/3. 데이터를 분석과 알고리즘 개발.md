분석 자원(IaaS)과 MSA, 웹 환경에서 데이터를 분석하고 알고리즘을 개발, 적용, 활용할 수 있는 체계를 구축하는 것은 현대 데이터 과학과 소프트웨어 개발의 중요한 과제 중 하나입니다. 이를 위해 여러 구성 요소를 통합하여 효과적인 환경을 만드는 방법을 설명하겠습니다.

### 1. 인프라 구성 (IaaS)

IaaS(Infrastructure as a Service)는 클라우드 서비스 제공자가 제공하는 가상화된 컴퓨팅 자원입니다. 이를 통해 사용자는 물리적 하드웨어를 관리할 필요 없이 서버, 스토리지, 네트워크 자원 등을 사용할 수 있습니다. 대표적인 IaaS 제공자로는 AWS, Azure, Google Cloud Platform(GCP) 등이 있습니다.

#### 주요 요소:

- **가상 서버 (EC2, VM)**: 데이터 분석 및 알고리즘 개발을 위한 컴퓨팅 파워 제공.
- **스토리지 (S3, Blob Storage)**: 대용량 데이터 저장 및 관리.
- **네트워킹**: 가상 네트워크를 통해 보안과 접근 제어를 관리.

### 2. MSA (Microservices Architecture)

MSA는 애플리케이션을 독립적으로 배포 가능한 작은 서비스들로 나누는 아키텍처 스타일입니다. 각 서비스는 특정 기능을 담당하며, 서로 독립적으로 배포 및 확장이 가능합니다.

이러한 MSA 를 이해하기 위해서는 `Monolithic Architecture` 와 등장배경에 대해 간략하게 이해를 하면 좋습니다. 

#### 2.1. Monolitic Architecture

`MSA` 가 등장 하기 이전에 사용하던 구조로 소프트웨어의 모든 구성요소가 한 프로젝트에 통합되어있는 형태를 의미한다. 

웹 개발을 예로들면 기능별 모듈을 개발하고 개발된 모듈을 웹 애플리케이션에 하나의 결화물로 패키징하여 배포하는 형태를 의미하며 주로 `WAR` 파일로 빌드되어 `WAS(예 : Apache Tomcat)` 등에 배포하는 형태로 주로 소규모 프로젝트에 사용합니다. 

이 아키텍처의 장점과 단점을 한번 정리해보겠습니다. 

##### 2.1.1. 장점

- 소규모 프로젝트에 적합
- 하나의 프로젝트에서 관리되므로 초기 프로젝트 구조의 복잡도가 낮은 편

##### 2.1.2. 단점

- 부분의 장애가 전체 서비스의 장애로 확대
- 부하가 많은 기능의 부분적인 확대(Scale-out) 이 어려움
- 서비스가 커짐에 따라 복잡도가 높아지며 이는 장애의 영향도 파악에 어려움을 줌
- 배포에 오랜시간이 걸림
- 한 언어에 종속적임

#### 2.2. MSA

##### 2.2.1. 등장 배경

이러한 `Monolithic Architecture` 의 단점을 보완하고자  나온것이 `Micro Service Architecture(MSA)` 입니다.  기존의 물리적인 서비스를 올리던 On-Promise 서버 기반의 아키택처에서 클라우드 환경을 이용하여 서버를 구성하는 클라우드 (또는 Container) 기반 아키텍처로 전환되어가고 있습니다.

##### 2.2.2. 서비스간 상호작용

하나의 서비스를 도메인 또는 유의미한 단위의 애플리케이션으로 나누어 서비스하고 각 서비스간의 상호작용은 HTTP 프로토콜을 이용한 API 의 직접 호출 또는 Redis, Memcahed 같은 Inmemory 기반의 데이터 공유, RabbitMQ, Kafka 같은 Message Stream (또는 Message Queue) 방식을 이용해 서비스간 상호 작용합니다. 

이런 MSA 에도 장점과 단점이 존재합니다. 

##### 2.2.3. 장점

- 각 서비스가 모듈화 되어있어 모듈끼리 별도의 API 또는 메시지 스트림을 통해 통신하며 이는 각각의 서비스 개발을 빠르개하고 해당 애플리케이션 도메인에 전문적인 지식을 갖은 사람이라면 쉽게 유지보수할 수 있습니다. 

- 팀 단위로 기술 스택을 다르게 가져갈 수 있습니다. 예를 들면 웹 개발에 최적화된 프레임워크를 제공하는 Java를 사용하던가 고성능을 필요로하는 서비스에서는 C 또는 C++ 을 사용하고, 블록체인 기술에서는 node.js / python 등을 사용하여 모듈 개발과 연동에 무리가 없습니다. 

- 분리된 애플리케이션이므로 각각의 애플리케이션이 별도의 라이프사이클을 갖으며 독립적인 배포가 가능합니다. 따라서 하나의 서비스 장애가 다른 서비스의 장애로 전파되는것을 최대한 방지할 수 있으며 가벼운 애플리케이션을 유지하므로 빌드의 성능이 향상되고 고객에게 최적의 사용자 경험을 신속하게 제공할 수 있습니다. 

- 애플리케이션이 분리되어있으므로 부하가 많은 애플리케이션은 독립적으로 Scale-Out 이 가능하며 자원 사용에 있어 유리한 부분이 많습니다. 

- 서비스간 통신은 내부망에서 통신하고 사용자 경험을 위한 API 는 External Gateway 에서 진행하므로 불필요한 접근을 악의적인 접근으로부터 보호할 수 있습니다. 

##### 단점

- 기존 아키텍처에 비해 상대적으로 복잡도가 높습니다. 서비스가 분산되어있기때문에 서비스간 상호작용을 위한 내부통신 인프라를 구성해야하며 장애와 서버 부하등이 있을때 트랜잭션의 유지와 장애 발생시 즉각적인 대응을 위한 별도의 시스템이 필요로 합니다. 

- 각 서비스별로 DB를 갖으므로 데이터의 일관성을 유지하는것이 어렵습니다. 

- 서비스가 분리되어있으므로 다른 서비스간 상호작용이 필요로하는 시스템과의 통합 테스트가 어려우며 장애 포인트에 대한 추적이 쉽지 않습니다. 

- 이러한 MSA 는 운영환경에 재배포한다고하면 다른 서비스간 연계가 정상적으로 이루어지고 있는지 파악하기 쉽지 않습니다. 

이러한 장/단점으로 인해 가트너사에서는 MSA 에 필요한 필수 요건들에 대해 정리하였으며 아래와 같습니다. 

	![[msa_components.png]]

위 그림과 같이 상당히 복잡한 구조의 컴포넌트들을 갖고 있으며 이는 `Monolithic Architecture` 에 비해 상대적으로 높은 복잡도를 제공합니다.

하지만 이러한 구성이 안정적으로 구성된다고 하면 사용자에게 더 좋은 사용자경험을 더욱 빠르게 제공할 수 있으며 장애 발생시에 장애가 전체로 전파되는것을 방지하여 사용자가 서비스 이용에 불편함이 없도록 서비스하는것이 가능해집니다.

#### 2.3. 주요 요소

- **서비스 디커플링**: 각 서비스는 독립적으로 배포 및 확장 가능.
- **API 게이트웨이**: 클라이언트와 서비스 간의 통신을 관리.
- **컨테이너화 (Docker, Kubernetes)**: 서비스의 이식성과 확장성 향상.
- **오케스트레이션 (Kubernetes)**: 컨테이너 배포, 확장, 관리를 자동화.

이 외에도 모니터링을 위한 텔레메트리 시스템과 메일발송, 영속성유지, SMS 등을 제공하는 백킹 서비스 그리고 서비스간 통신을 위한 서비스 메시같은 요소들이 있습니다.

### 3. 웹 환경

웹 환경에서 데이터를 분석하고 알고리즘을 개발 및 적용하기 위해서는 사용자 인터페이스와 백엔드 서비스를 구축해야 합니다.

#### 주요 요소:

- **프론트엔드**: React, Angular, Vue.js 등을 사용하여 데이터 시각화 및 사용자와의 상호작용을 구현.
- **백엔드**: Django, Flask, Express.js 등을 사용하여 API와 비즈니스 로직을 구현.
- **데이터베이스**: 관계형 (PostgreSQL, MySQL) 및 비관계형 (MongoDB, Redis) 데이터베이스 사용.
- **CI/CD 파이프라인**: Jenkins, GitLab CI/CD 등을 사용하여 코드의 지속적인 통합 및 배포 자동화.

### 4. 데이터 분석 및 알고리즘 개발

데이터 분석 및 알고리즘 개발을 위한 툴과 환경을 설정합니다.

#### 주요 요소:

- **분석 도구**: Jupyter Notebook, JupyterLab, VSCode 등.
- **프로그래밍 언어**: Python, R 등.
- **라이브러리 및 프레임워크**: Pandas, NumPy, Scikit-learn, TensorFlow, PyTorch 등.
- **모델 배포**: Flask, FastAPI, TensorFlow Serving, TorchServe 등을 사용하여 모델을 API로 배포.

데이터 분석을 위한 파이썬 라이브러리는 아래 URL 에서 확인할 수 있습니다. (메뉴 확인)

> [Python Libraries](https://www.unite.ai/10-best-image-processing-libraries-in-python/)

이렇게 분석된 데이터의 배포, 제공을 관리하기 위한 방법으로 Git 또는 DVC(Data Version Control) 을 이용해서 관리가 가능하다. (Data lake 또한 같은 것이다.)
### 통합 체계 예시

#### 1. 인프라

- **AWS**: EC2 인스턴스를 사용하여 JupyterLab 서버를 설치하고 S3를 사용하여 데이터 저장.
- **Docker**: 분석 환경을 Docker 컨테이너로 패키징.

##### 1.1. Docker 를이용한 JupyterLab 구축

1. **Dockerfile 작성 & Build**

먼저 아래와 같이 도커파일을 작성하여 필요한 환경과 패키지를 설치

```Dockerfile
FROM jupyter/datascience-notebook:latest

# 필요한 Python 패키지 설치
RUN pip install --no-cache-dir \
	numpy pandas scikit-learn matplotlib seaborn

WORKDIR /home/jovyan/work
# 컨테이너 시작 시 JupyterLab 실행 
CMD ["start.sh", "jupyter", "lab", "--ip=0.0.0.0", "--no-browser", "--allow-root"]
```

도커 파일에 자신이 사용할 라이브러리 또는 프레임워크 정의한다음 도커 이미지를 빌드 합니다.

```shell
docker build -t my-jupyter .
```

2. **컨테이너의 실행**

아래 명령어를 이용해서 Jupyter Notebook 컨테이너 이미지를 실행합니다.

```shell
docker run -d -p 8888:8888 -v $(pwd)/work:/home/jovyan/work my-jupyter 
```

3. **Jupyter Notebook 연결**

브라우저에서 `http://${jupyter host}:8888` 로 접근하여 터미널에 출력된 토큰을 사용하여 접속합니다. 

- 토큰설정하는 환경변수에 대해서는 별도로 알아봐야 할 듯 합니다.

##### 1.2 Kubernetes 를 이용한 JupyterLab 구축

1. **Deployment 파일 작성**

먼저 `jupyterlab-deployment.yml` 을 작성합니다.

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
	name: jupyterlab-deployment
spec:
	replicas: 1
	selector:
		matchLabels:
			app: jupyterlab
	template:
		metadata:
			labels:
				app: jupyterlab
		spec:
			containers:
			- name: jupyterlab
		      imabe: my-jupyterlab
		      ports:
		      - containerPort: 8888
		      volumeMounts:
		      - name: workdir
		        mountPath: /home/jovyan/work
		    volumes:
		    - name: workdir
		      hostPath:
			      path: $(pwd)/work
```

2. **Service 파일 작성**

다음으로 `jupyterlab-service.yml` 을 작성합니다. 

```yaml
apiVersion: v1
kind: Service
metadata:
	name: jupyterlab-service
spec:
	selector:
		app: jupyterlab
	ports:
		- protocol: TCP
		  port: 8888
		  targetPort: 8888
    type: LoadBalancer
```

3. **Kubernetes 클러스터에 배포**

```shell
kubectl apply -f jupyterlab-deployment.yml
kubectl apply -f jupyterlab-service.yml
```

이렇게 배포가 완료되면 외부 IP 를 통해 접근이 가능하며 외부 IP는 `kubectl get serivces` 명령어로 확인이 가능합니다. 

> 이렇듯 분석환경을 구성하기 위해서는 Docker Container 또는 Kubernetes 의 지식이 필요로 합니다. 

#### 2. MSA

- **서비스 설계**: 데이터 수집, 전처리, 분석, 모델 학습, 예측 서비스로 분리.
- **Kubernetes**: 각 서비스를 컨테이너로 배포하고 관리.

#### 3. 웹 환경

- **프론트엔드**: React를 사용하여 데이터 시각화 대시보드 구축.
- **백엔드**: Flask를 사용하여 분석 결과와 모델 예측을 제공하는 REST API 구축.
- **데이터베이스**: PostgreSQL을 사용하여 분석 결과 저장.

#### 4. 데이터 분석 및 알고리즘 개발

- **JupyterLab**: 데이터 탐색, 분석, 모델 개발.
- **CI/CD 파이프라인**: GitHub Actions를 사용하여 코드의 테스트 및 배포 자동화.

### 예시 워크플로우

1. **데이터 수집**: 데이터를 S3에 저장.
2. **전처리**: 데이터 전처리 서비스를 통해 데이터를 정제하고 변환.
3. **분석 및 모델링**: JupyterLab에서 데이터를 분석하고 모델 개발.
4. **모델 배포**: 개발된 모델을 Docker 컨테이너로 패키징하여 Kubernetes 클러스터에 배포.
5. **예측 서비스**: REST API를 통해 모델 예측 결과 제공.
6. **데이터 시각화**: React 대시보드를 통해 실시간 데이터 및 예측 결과 시각화.

이와 같은 체계를 통해 데이터 분석과 알고리즘 개발 및 배포의 전 과정을 효과적으로 관리할 수 있습니다.

## 참고

- [Machine Operations Infrastructure Stack](https://ml-ops.org/content/state-of-mlops)