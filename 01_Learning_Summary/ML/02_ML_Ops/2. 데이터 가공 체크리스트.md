
데이터를 가공하기 위해서는 어떤것들을 준비해야하는지 정리해보겠습니다. 

## 데이터 전처리

데이터 분석을 위해 수집한 데이터를 정리 및 변환하는 과정을 의미하며 다음과 같은것들을 위해 필요로 합니다. 

- **데이터 형식 표준화** : 다양한 형식의 구조(정형/반,비정형)로 수집되는 데이터는 모델링에 적합하게 만들기 위해 표준 형식으로 변환 및 필요한 형태로 조정
- **이상치 및 누락된 값 처리** : 데이터 전처리를 통해 예상 데이터 범위에서 기준을 벗어난 아주 작은 값이나 큰 값인 이상치를 처리하고, 실제 데이터에 누락된 값을 대체하는 등 데이터의 완전성을 유지
- **데이터의 품질 향상** : 노이즈나 신뢰할 수 없는 값을 포함하는 문제를 가질 수 있기 때문에 전처리를 통해 해결하고 품질을 향상시킴
-  **모델 성능 향상** : 모델이 데이터의 패턴이나 관계를 더 잘 파악하고 분류하는데 도움을 줌
- **특성 엔지니어링** : 기존 특성 변경 및 신규 특성 생성에 사용될 수 있으며 유의미한 정보를 추출하는데 도움이 됨

### 정형/비정형 데이터

일단 전처리 과정에대해 알아보기전에 비정형 데이터에 간략하게 알아보고 넘어가겠습니다.

정형 데이터는 미리 정의된 구조 또는 모델을 따르는 데이터입니다. 일반적으로 아래와 같은 구조로 구성되어있습니다. 

이 예시는 CSV 파일의 구조를 예시로 들었습니다.
```
idx,name,count,width,height
1,A,1,100px,200px
2,B,2,120px,203px

...

```

반정형 데이터는 기존 방식으로 캡처되거나 형식이 지정되지 않은 데이터를 의미하며 고정된 스키마가 없기때문에 정형 데이터와는 다르게 테이블 형식의 데이터모델 또는 RDBMS의 형식을 따르지 않습니다. 

```html
<div>
	<p>P 태그</p>
</div>
```

위와같이 html, json, xml 등 구조에 따라 저장되지만 데이터의 형식과 구조가 변경될 수 있습니다.



비정형 데이터는 비구조화 데이터로 미리 정의된 데이터 모델이 없거나 정형화된 방식으로 정리되지 않은 정보를 의미합니다.

사진, 동영상, 음성 등이 대표적이며 분석할 대상을 추출하는 작업을 어노테이션이라고 합니다. 이렇게 추출된 정보를 효율적으로 분류하기 위해 주석을 부여하는 작업을 라벨링 혹은 주석화라고 합니다.

### 데이터 전처리 과정

1. **데이터 수집 및 클리닝** : 웹크롤링, API 등을 통해 데이터를 수집하고 누락된 값이나 오류가 없는지 데이터 클리닝을 통해 확인하고 불필요한 데이터를 처리
2. **데이터 변환** : 스케일링 또는 정규화작업을 통해 모델링 작업에 적합한 데이터로 변환
3. **특성 엔지니어링** : 모델의 성능의 향상을 위해 데이터에 새로운 특성을 생성하거나 유용한 특성을 추출
4. **데이터 통합 및 샘플링** : 수집된 데이터를 통합 및 단일 데이터셋으로 만들고, 데이터의 균형을 맞추기 위해 데이터 샘플링을 통해 데이터셋의 크기를 줄임
5. **데이터 저장 및 품질 검증** : 데이터 웨어하우스나 데이터베이스를 사용해 가공된 데이터를 저장하고, 데이터 품질 보장을 위해 데이터 검증 및 품질 지표를 체크

일반적으로 데이터의 수집(1) -> 정제(2, 3) -> 통합 (4) -> 데이터의 축소(4) -> 데이터의 변환(4) 의 작업을 거치고 중복값 제거 및 결측값 보정, 데이터 연계/통합, 노이즈 제거, 구조변경, 벡터와 등을 진행합니다.

#### 데이터 정제 기술

이러한 전처리 중 데이터를 정제하기 위해서는 빠르고 안정적으로 정제하고, 데이터 처리의 성능을 보장하기 위해 분산 처리 시스템 기반의 인메모리 컴퓨팅 기술을 사용합니다.

##### 참고
-  [데이터 정제 및 세분화](https://mangtoman.tistory.com/entry/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%95%EC%A0%9CData-Cleansing%EC%99%80-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%84%B8%EB%B6%84%ED%99%94Data-Segmentation)
-  [데이터 전처리](https://yssa.tistory.com/entry/Big-Data-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%84%EC%B2%98%EB%A6%AC)


1. **ELT** : 수집이 필요한 데이터를 추출, 가공하여 데이터 웨어하우스 및 데이터 마트에 저장하는 기술
	 - 관련 자료 및 솔루션 : https://www.ibm.com/kr-ko/topics/elt, https://www.integrate.io/ko/blog/top-7-etl-tools-ko/
2. **맵 리듀스** 
	- 대용량 데이터셋을 병렬 컴퓨팅 처리하기위해 만들어진 프레임워크로 모든 데이터를 키-값 쌍으로 구성
	- 데이터를 추출하는 Map 기술과 중복이 업게 처리하는 리듀스 기술로 구성되었으며 배치 형태 처리방식으로 데이터가 많아지면 성능이 저하됨
3. **스파크/스톰** : 인 메모리 기반 데이터 처리방식으로 맵리듀스의 성능을 개선하여 실시간, 배치 처리 모두 가능
4. **CEP** : 실시간 이벤트에 대한 데이터를 처리하는 기술로 IOT 센싱 데이터, 음성 데이터 등 실시간으로 처리하는 기법 
	- 관련 자료 및 솔루션 : https://ssongit.tistory.com/1
5. **피그** : 대용량 데이터 집합 분석 플랫폼으로 하둡을 이용해서 맵리듀스를 하기 위한 자체어너 피그라틴을 제공
6. **플럼** : 로그 데이터를 수집하고 처리, 실시간에 근접하여 데이터를 전처리 가능
	- 관련 자료 및 솔루션 : https://flume.apache.org/

### 데이터 전처리 준비사항

- **요구사항 정의** : 데이터의 가공 목적과 필요한 결과물에 대해 요구사항을 상세히 정리하고 문서화
- **데이터 수집 및 정리** : 데이터의 구조 및 소스에 대한 정보를 준비 

### 데이터 전처리 주의사항

- 수집된 데이터에 개인정보와 같은 민감데이터가 존재하는지에 대한 여부를 파악하고 보안을 위해 어떤 절차가 필요한지 체크
- 데이터의 가공범위가 늘어날때를 대비해 변경관리에대한 절차가 필요


## 데이터 전처리 저장

전처리된 데이터를 저장하는 방법에는 여러가지가 있는데 각각의 방법은 형식, 크기, 활용 목적등에 따라 선택될 수 있으며 일반적으로 다음과 같은 방법(파일)들이 있습니다. 

1. **CSV** : 텍스트 형식으로 데이터를 저장하며 데이터 크기가 작은경우 적합
2. **Excel** : 데이터 분석과 보고서 작성에 유용하며, Excel의 기능을 활용할 수 있음
3. **RDBMS** : 복잡한 쿼리를 이용해 조회가 가능하며 데이터의 일관성 및 무결정 유지에 유리
4. **HDF5** : 대규모 데이터를 효율적으로 저장하고 빠르게 접근이 가능하며 데이터를 계층적 구조로 관리
5. **Parquet** : 컬럼 형식의 저장박식으로 대규모 데이터에 적합하며 고속 처리와 압축기능 제공
6. **Json** : 웹 애플리케이션과 호환성이 높으며 반정형데이터를 표현하기 좋고 인간이 읽기 쉬운 형식
7. **Pickle** : Python 객체를 직렬화하여 저장하며 Python 환경에서만 사용이 가능
8. **Feature** : 빠른 I/O 성능을 제공하는 바이너리 형식

이와 같은 다양항 방법을 통해 전처리된 데이터를 적절하게 저장하고 각 방법의 장단점을 고려하여 가장 적합한 방식을 선택하는것이 중요합니다. 

> 이 부분은 Chat GPT 를 통해 정리하였음




