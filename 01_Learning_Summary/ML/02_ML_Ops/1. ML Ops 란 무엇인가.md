`MLOps` 에 대해 알아보기 전에 먼저 `DevOps` 에 대해 가볍게 알아봅시다.

## DevOps

데브옵스는 기존 개발과 운영팀(ITO) 의 갈등을 해결하기 위해 고안된 협업 방식으로 애플리케이션을 개발, 배포, 실행하는 프로세스나 기술을 효율적으로 관리하기 위한 방법이다. 이와 같은 모델을 채택하여 AI 산업에서 고안된 방안이 MLOps 입니다.
## MLOps (Machine Learning Operations)

MLOps 는 데이터 세트를 준비하고 이를 분석하는 AI 모델을 만드는 데이터 사이언티스트를 지원하며, 여기에는 데이터세트를 모델링하여 체계적으로 자동 처리하기 위한 머신러닝 엔지니어도 포함합니다.

![[ml_ops.png]]

먼저 MLOps 에 대해 자세히 알아보기전에 관련 업종에 대해 간략하게나마 정리해보고 넘어가겠습니다.
###  데이터 엔지니어 & 머신러닝 엔지니어 

#### 데이터 엔지니어

데이터 엔지니어링은 데이터를 대규모로 수집하고 저장 및 분석하기 위한 시스템을 설계하고 구축하는 일을합니다.
원시 데이터를 수집, 관리하고 데이터 사이언티스트와 비즈니스 분석가가 해석할 수 있는 유용한 정보로 변환하는 시스템을 구축하기 위해 다양한 환경에서 작업을 합니다.

궁극적인 목표 : 조직이 **데이터를 사용**하여 성과를 평가하고 최적화할 수 있도록 **데이터에 액세스 할수 있도록 하는 것**입니다.

이러한 데이터 엔지니어는 일반적으로 데이터 준비에 참여하고 아키텍처를 개발, 구성, 테스트 및 유지관리 합니다. API 를 만들고 통합할 수 있는 기술적 지식이 필요하고 데이터 파이프라인과 성능 최적화에 대한 이해가 필요합니다.
##### 하는 일

- 비즈니스 요구사항에 맞는 데이터셋 획득
- 데이터를 유용하고 실행 가능한 정보로 변환하는 알고리즘 개발
- 데이터베이스 파이프라인 아키텍처 구축, 테스트 및 유지관리
- 새로운 데이터 유효성 검사 방법 및 데이터 분석 도구 만들기

##### 기본 역량

- **코딩** : 데이터 엔지니어의 필수적으로 학습해야하는 기술로 `SQL`, `NoSQL`, `Python`, `Java`, `R`, `Scala` 을 일반적으로 학습 해야함
- **관계형 및 비관계형 DBMS** : 데이터 저장을 위한 일반적인 기술로 작동 방식에 대해 학습해야 함
- **ELT(추출, 변환 및 로드)** : 데이터베이스 및 기타 소스에서 데이터 웨어하우스와 같은 단일 레포지토리로 데이터를 이동하는 프로세스로 일반적으로 사용하는 도구로는 `Xplenty`, `Stitch`, `Alooma`, `Talend` 가 있다.
- **자동화 및 스크립팅** : 반복 작업을 자동화하는 스크립트를 작성할 수 있어야 함 
- **머신 러닝** : **데이터 사이언티스트의 관심사**이지만 효율적인 협업과 요구사항을 잘 이해하기 위해 기본 개념을 파악하고 있는것이 도움 됨
- **빅데이터 도구** : 일반 데이터뿐 아니라 빅데이터를 관리하는 임무를 종종 맡으므로 `Hadoop`, `MongoDB`, `Kafka` 등의 기술을 학습
- **클라우드 컴퓨팅** : 클라우드 스토리지와 컴퓨팅에 대해 이해해야 함. 기본적으로 `IaaS`와 `Object Storage` 에 대한 이해와 `k8s` 같은 컨테이너 환경의 이해도 필요
- **데이터 보안** : 데이터의 손실 또는 도난으로부터 보호하기 위한 관리 방법을 알아야 함

##### 데이터 과학자 vs 데이터 분석가 vs 데이터 엔지니어

| 데이터 과학자                   | 데이터 엔지니어                     | 데이터 분석가                                       |
| ------------------------- | ---------------------------- | --------------------------------------------- |
| 복잡한 데이터를 분석하고 해석          | 데이터 준비에 참여                   | 숫자 데이터를 분석하고 이를 사용하여 더 나은 의사결정을 내릴 수 있도록 지원   |
| 고급 통계 분석, 머신러닝에 대한 이해가 필요 | 아키텍처를 개발, 구성, 테스트 및 유지 관리    | 통계 지식을 기반으로 비즈니스에 대한 이해와 함께 데이터 처리, 모델링 및 레포팅 |
|                           | API 를 만들고 통합할 수 있는 기술적 지식 필요 |                                               |
|                           | 데이터 파이프라인과 성능 최적화에 대한 이해가 필요 |                                               |

#### 머신러닝 엔지니어 

알고리즘을 사용하여 인간이 학습하는 방식을 복제하는 방식으로 데이터를 해석하며 기계의 학습 정확도를 개선하고 해당 학습을 기반으로 데이터를 사용자에게 제공하는 것을 목표로 합니다.

데이터 과학 팀의 핵심 구성원 역할로 머신러닝을 담당하는 인공지능을 연구, 구축, 설계하고 기존 인공지능 시스템을 유지 및 개선합니다.

##### 하는일

- 기계 학습 알고리즘 구현
- AI 시스템 실험 및 테스트 실행
- 기계 학습 시스템 설계 및 개발
- 통계 분석 수행

##### 기본 역량

- 기계학습 기본 이론 및 알고리즘에 대한 이해와 확률과 통계, 선형대수학 등 수학적 개념 필수 학습
- 선형회귀, 로지스틱회귀, SVM 등 머신러닝 알고리즘의 이해
- 지도학습, 비지도학습, 강화학습 등을 이용한 다양한 주제를 선정
- Scikit-Learn, Theano, Tensorflow, PyTorch 등 기계학습에 필요한 라이브러리

#### 데이터 엔지니어 vs 머신러닝 엔지니어 

![[summary/01_Learning_Summary/ML/02_ML_Ops/image/ml.png]]

### MLOps 를 위해서는

MLOps 는 로우 성능과 엄격한 관리 차원에서도 쉽지 않은 과제로 방대하면서 지속적으로 증가며 실시간으로 변화하는 데이터셋을 기반으로 AI 모델을 제대로 개발하기 위해 수 차례의 실험, 미세조정, 결과를 모니터링 하도록 지원해야 합니다.

기업 성장속도에 맞춤 강력한 AI 인프라가 필요하며 이 떄문에 NVIDIA DGX 시스템, CUDA-X 를 비롯해 엔비디아 소프트웨어 허브인 NGC 의 기타 소프트웨어 컴포넌트를 사용합니다.

> DGX 시스템 : 대규모 AI 모델의 학습, 추론, 분석에 성능 최적화된 H100 SXM 기반 GPU 서버
> CUDA-X : 대화형 AI, 추천 시스템, 컴퓨터 비전용 고성능 GPU 가속 애플리케이션을 구축하는 연구자와 소프트웨어 개발자를 위한 딥러닝 소프트웨어 스택
> [NGC](https://www.nvidia.com/ko-kr/gpu-cloud/) : 엔터프라이즈 서비스, 소프트웨어, 관리도구, 엔드 투 엔드 AI 및 디지털 트윈 워크플로우 지원을 위한 포탈 

#### 데이터 사이언티스트를 위한 라이프사이클 모니터링

AI 인프라가 구축된 엔터프라이즈 데이터센터는  아래의 MLOps 의 소프트웨어 스택요소를 레이어링 할 수 있습니다.

- 데이터 소스와 가공된 데이터셋
- 사용 내역과 특성이 태깅된 AI 모델 리포지토리
- 라이프사이클을 통해 데이터세트, 모델과 실험을 관리하는 자동 ML 파이프라인
- k8s 기반 소프트웨어 컨테이너

데이터 사이언티스트는 외부 소스와 내부 데이터 레이크에서 데이터셋을 자유롭게 잘라 붙일 수 있어야하며 작업과 데이터셋은 신중하게 라벨링하고 추적될 수 있어야 합니다.

양질의 모델을 만들기 위해서는 지속적으로 다양한 시도와 반복작업을 해야하며 이를 위해서는 샌드박스와 견고한 리퍼포지토리가 필요합니다.

프로토타입, 테스트, 프로덕션을 통해 데이터 세트와 모델을 실행하는 머신러닝 엔지니어들과 협업할 방법을 찾아야 하며 모델을 쉽게 해석하고 재생산할 수 있도록 자동화와 세심한 주의가 필요한 프로세스입니다.

![[ml_pipeline.png]]

### MLOps 입문 3가지 단계

가트너 수석 분석가 슈방스 바쉬스는 MLOps 에 입문하는 3가지 단계를 설명한 백서를 집필하였으며 아래와 같습니다.

1. 이해관계자들과의 공동의 목표를 설정
2. 소유권을 정리한 조직도를 작성
3. 업무분장

가트너의 경우 업무분장 리스트는 10개가 넘으니 아래 그림으로 참고하세요

#### 가트너의 업무분장 리스트

![[ml_division_of_work.png]]

### MLOps 의 목표 및 조건

#### MLOps 의 조건

1. 지속적 학습

 - 실시간 파이프라인 트리거 기반으로 새로운 데이터를 사용하여 다시 학습 하는 것 
 - 새로운 데이터 학습을 위한 Data and Model Validation 이 필수
	 - Data Validation : 데이터 검증에 실패하면 신규 모델의 배포를 중지해야함 
	 - Model Validation : 모델이 새로운 데이터로 재학습을 마치고 운영환경에 반영되기 전 평가되고 검증

2. 지속적 통합

- 새로운 코드 변경사항이 정기적으로 빌드 및 테스트뒤어 공유 리포지토리로 통합

3. 지속적 배포 및 제공

-  운영팀이 리포지토리의 애플리케이션을 실시간으로 운영환경으로 배포
- 학습 및 검증된 모델을 온라인 예측용 서비스로 제공

#### MLOps 의 목표

학습모델 개발과 운영에서 사용되는 문제의 반복을 최소화하면서 비즈니스 가치를 창출하며 데이터 과학자 또는 분석가가 모델링에 집중할 수 있도록 안정된 인프라를 만들고 자동으로 운영할 수 있도록 제공해야 합니다.

또한, 빠른 시간에 적은 리스크로 운영환경까지 배포할 수 있도록 기술적 마찰을 줄이도록 하는것을 목표로 합니다.

### 기계학습을 위한 Data Science 단계

1. 데이터 추출(Data Extraction) : 데이터 소스에서 연관데이터를 추출
2. 데이터 분석(Data Analysis) : 데이터의 이해를 위한 탐사적 데이터 분석 수행 및 모델에 필요한 데이터 스키마 및 특성 이해
3. 데이터 준비(Data Preparation) :  데이터 학습을 위한 검증 및 테스트셋 분할 
4. 모델 훈련(Model Training) : 다양한 알고리즘의 구현, 하이퍼 파라미터 조정 및 적용하며 Output 으로 학습된 모델이 나옴
5. 모델 평가(Model Evaluation) : 데이터 준비과정에서 추출한 테스트셋을 이용해 모델을 평가하며 Output 으로 모델의 평가 Metric 이 나옴
6. 모델 검증(Model Validation) : 기준치 이상의 모델 성능이 검증되고, 배포 가능한 수준인지 검증
7. 모델 서빙(Model Serving) : 온라인 예측을 제공하기 위해 RestAPI 를 포함한 마이크로 서비스 및 배치 예측 시스템
8. 모델 모니터링(Model Monitoring) : 모델 예측 성능을 모니터링

위와 같은 프로세스의 자동화 수준에 따라 기계학습 시스템의 수준을 평가해볼 수 있으며 Google에서는 가장 보편적인 수동단계부터 CICD Pipeline 을 모두 자동화하는 단계까지 성숙도를 세 단계로 나누어 제시합니다.

#### Google 제시한 기계학습 프로세스 성숙도

> 기계학습 프로세스 성숙도의 이미지는 Google Cloud MLOps 에서 발최
##### Lv.0 - 수동 프로세스

기계학습모델을 빌드하고 배포하는 과정의 전체가 수종으로 이루어지는 프로세스이며 아래와 같은 특성을 갖습니다.

![[ml_process_lv0.png]]

- **수동프로세스** : 데이터의 추출 및 분석, 모델 학습, 검증을 포함한 모든 단계가 수동적
- **기계학습과 운영을 분리** : 모델을 만드는 데이터 과학자와 모델을 예측 서비스로 제공하는 엔지니어를 분리 
- **드문 배포** : 새 모델 버전의 배포가 비정기적으로 발생
- **CICD 불필요** : 모델의 변경이 적고 배포가 자주 없으므로 CICD가 불필요
- **모니터링 부재** : 로그나 모델의 예측 성능등을 모니터링 불가하여 모델의 성능이 저하되거나 이상동작을 감지하지 못함

##### Lv.1 - 기계학습 파이프라인 자동화

기계학습 모델의 지속적인 훈련을 목표로 기계학습 파이프라인을 자동화합니다.

![[ml_process_lv1.png]]

이 모델은 Lv.0(수동프로세스)에서 아래 4가지의 추가 구성요소를 갖습니다.

- **Data and Model Validation** : 새로운 데이터를 통해 새로운 모델을 지속적으로 학습하기위한 필수단계
- **Feature Store** : 사용 가능한 모든 `Feature` 를 모아놓은 저장소 (최신화된 데이터)
- **Metadata Management** : 기계학습 파이프라인의 실행정보, 데이터 및 아티팩트의 정보를 저장
- **ML Pipeline Triggers** : 모델을 재학습 시키는 파이프라인의 자동화

이러한 구성요소를 추가한 Lv.1 은 아래와 같은 특성을 갖습니다.

- **빠른 실험** : 실험을 빠르게 반속하고 전체 파이프라인을 운영환경에 빠르게 배포
- **파이프라인 배포** : 개발 환경에서 사용된 파이프라인이 운영환경에서도 사용가능
- **지속적 학습** : 새로운 데이터를 사용하여 프로덕션 모델이 자동으로 학습
- **지속적 제공** : 새로운 데이터로 학습하고 검증된 모델을 지속적으로 제공

##### Lv.2 CICD Pipeline 자동화

Lv.2 는 Lv.1 에서 CICD 측면을 집중적으로 강화한 시스템을 의미합니다.

![[ml_process_lv2.png]]

이 모델은 Lv.1(기계학습 파이프라인 자동화) 에서 아래 3가지 차이점을 갖습니다.

- **지속적 통합** : 리포지토리로 코드가 커밋이나 푸시될때 파이프라인과 구성요소가 빌드, 테스트 및 패키징 됨
- **지속적 배포 및 제공** : 배포전 모델과 인프라호환성을 확인 및 서비스 API 호출을 테스트 
- **파이프라인 오케스트레이션** : 파이프라인의 자동화된 설정, 관리, 조정 가능